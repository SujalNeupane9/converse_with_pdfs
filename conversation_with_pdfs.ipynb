{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UANYaySPNEEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e5604d-c450-4473-cb38-f38f209b7781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -U langchain PyPDF2 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U InstructorEmbedding faiss-cpu sentence-transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bJKfvede68_",
        "outputId": "feb3971b-2fd6-43aa-c5d6-8737b84b1100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "tmh2zjJTOg2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_text(pdf_docs):\n",
        "  text = \"\"\n",
        "  for pdf in pdf_docs:\n",
        "    pdf_reader = PdfReader(pdf)\n",
        "    for page in pdf_reader.pages:\n",
        "      text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ViHOikzTOiBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_chunks(text):\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      #seperator='\\n\\n',\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap = 200,\n",
        "      length_function = len\n",
        "  )\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks"
      ],
      "metadata": {
        "id": "amWN8E5KOh-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectorstore(text_chunks):\n",
        "  embeddings = HuggingFaceInstructEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "  vectorstore = FAISS.from_texts(texts=text_chunks,\n",
        "                                 embedding=embeddings)\n",
        "  return vectorstore"
      ],
      "metadata": {
        "id": "8AJgE4nKOh7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conversation_chain(vectorstore):\n",
        "  llm = HuggingFaceHub(huggingfacehub_api_token = '....',repo_id='google/flan-t5-base',\n",
        "                       model_kwargs={\"temperature\":0.5,\n",
        "                                     \"max_length\":512})\n",
        "  memory = ConversationBufferMemory(memory_key='chat_history',\n",
        "                                    return_messages=True)\n",
        "  conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "      llm = llm,\n",
        "      retriever = vectorstore.as_retriever(),\n",
        "      memory=memory\n",
        "  )\n",
        "  return conversation_chain"
      ],
      "metadata": {
        "id": "XQQMArKhREc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_userinput(user_question, conversation):\n",
        "    response = conversation({'question':user_question})\n",
        "    chat_history = response.get('chat_history', [])\n",
        "    if not chat_history:\n",
        "        chat_history = []\n",
        "    for i, message in enumerate(chat_history):\n",
        "        if i % 2 == 0:\n",
        "            print(f\"User:{message.content}\")\n",
        "        else:\n",
        "            print(f\"Bot:{message.content}\")\n"
      ],
      "metadata": {
        "id": "_Q2VpU8tREZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # process uploaded pdfs\n",
        "    pdf_docs = input(\"Enter path to pdfs separated by comma:\").split(\",\")\n",
        "\n",
        "    # create vectorstore\n",
        "    text_chunks = get_text_chunks(get_pdf_text(pdf_docs))\n",
        "    vectorstore = get_vectorstore(text_chunks)\n",
        "\n",
        "    # create conversation chain\n",
        "    conversation = get_conversation_chain(vectorstore)\n",
        "\n",
        "    # ask a question\n",
        "    user_question = input(\"Ask a question about your document:\")\n",
        "    if user_question:\n",
        "        handle_userinput(user_question, conversation)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2T34HInSVtP",
        "outputId": "b2cd3277-26e8-453f-d6d0-86fa5920d593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path to pdfs separated by comma:/content/CG-Unit 8.pdf\n",
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "Ask a question about your document:What are some surface rendering techniques?\n",
            "User:What are some surface rendering techniques?\n",
            "Bot:Constant intensity shading method Gouraud shading method Phong shading mehod (Normal vector interpolation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ddmK6TZ2jSRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}